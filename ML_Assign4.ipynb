{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "VFPVCEorqbRd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75eb475b-b64f-42ff-e687-98382d14f650"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:88: RuntimeWarning: invalid value encountered in reduce\n",
            "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Learning Rate: 0.1\n",
            "Best Regularization Parameter: 1e-15\n",
            "Best R2 Score: 0.5184322472390128\n",
            "Best Weights: [ 0.56223849  0.33693059 -0.92515723 -0.02385099 -0.0019705   0.02367814\n",
            "  0.03067171]\n",
            "Best Bias: 0.012151280644337983\n"
          ]
        }
      ],
      "source": [
        "# Q1\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "np.random.seed(42)\n",
        "n_samples = 1000\n",
        "X = np.random.rand(n_samples, 1)\n",
        "X = np.hstack([X + np.random.normal(0, 0.02, (n_samples, 1)) for _ in range(7)])  # Creating 7 correlated columns\n",
        "y = 3 * X[:, 0] + 2 * X[:, 1] - 5 * X[:, 2] + np.random.normal(0, 0.1, n_samples)  # Target variable with noise\n",
        "\n",
        "X_mean = np.mean(X, axis=0)\n",
        "X_std = np.std(X, axis=0)\n",
        "X = (X - X_mean) / X_std\n",
        "\n",
        "def ridge_regression(X, y, learning_rate, regularization_param, n_iterations=1000):\n",
        "    n_samples, n_features = X.shape\n",
        "    weights = np.zeros(n_features)\n",
        "    bias = 0\n",
        "\n",
        "    for i in range(n_iterations):\n",
        "        y_pred = np.dot(X, weights) + bias\n",
        "        residuals = y_pred - y\n",
        "\n",
        "        weights_gradient = (2 / n_samples) * (np.dot(X.T, residuals) + regularization_param * weights)\n",
        "        bias_gradient = (2 / n_samples) * np.sum(residuals)\n",
        "\n",
        "        weights -= learning_rate * weights_gradient\n",
        "        bias -= learning_rate * bias_gradient\n",
        "\n",
        "        if np.isnan(weights).any() or np.isnan(bias):\n",
        "\n",
        "            break\n",
        "\n",
        "    return weights, bias\n",
        "\n",
        "learning_rates = [0.0001, 0.001, 0.01, 0.1, 1, 10]\n",
        "regularization_params = [1e-15, 1e-10, 1e-5, 1e-3, 1, 10, 20]\n",
        "\n",
        "best_r2 = -np.inf\n",
        "best_params = None\n",
        "best_model = None\n",
        "\n",
        "for lr in learning_rates:\n",
        "    for reg in regularization_params:\n",
        "        try:\n",
        "            weights, bias = ridge_regression(X, y, learning_rate=lr, regularization_param=reg)\n",
        "            y_pred = np.dot(X, weights) + bias\n",
        "\n",
        "            if np.isnan(y_pred).any():\n",
        "                continue\n",
        "\n",
        "            r2 = r2_score(y, y_pred)\n",
        "\n",
        "            if r2 > best_r2:\n",
        "                best_r2 = r2\n",
        "                best_params = (lr, reg)\n",
        "                best_model = (weights, bias)\n",
        "        except Exception as e:\n",
        "            print(f\"Error for lr={lr}, reg={reg}: {e}\")\n",
        "            continue\n",
        "\n",
        "if best_params:\n",
        "    print(f\"Best Learning Rate: {best_params[0]}\")\n",
        "    print(f\"Best Regularization Parameter: {best_params[1]}\")\n",
        "    print(f\"Best R2 Score: {best_r2}\")\n",
        "else:\n",
        "    print(\"No valid parameters found.\")\n",
        "\n",
        "if best_model:\n",
        "    weights, bias = best_model\n",
        "    print(\"Best Weights:\", weights)\n",
        "    print(\"Best Bias:\", bias)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q2\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "hitters = pd.read_csv('Hitters.csv')\n",
        "\n",
        "hitters = hitters.dropna()\n",
        "le = LabelEncoder()\n",
        "hitters['League'] = le.fit_transform(hitters['League'])\n",
        "hitters['Division'] = le.fit_transform(hitters['Division'])\n",
        "hitters['NewLeague'] = le.fit_transform(hitters['NewLeague'])\n",
        "\n",
        "X = hitters.drop('Salary', axis=1)\n",
        "y = hitters['Salary']\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "linear_model = LinearRegression()\n",
        "ridge_model = Ridge(alpha=0.5748)\n",
        "lasso_model = Lasso(alpha=0.5748)\n",
        "\n",
        "linear_model.fit(X_train, y_train)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "models = {'Linear Regression': linear_model, 'Ridge Regression': ridge_model, 'Lasso Regression': lasso_model}\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{name}: MSE={mse:.2f}, R2={r2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDOsrpwu0ACl",
        "outputId": "dba3a263-e327-4709-a8ba-169c48c961e9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Linear Regression: MSE=128284.35, R2=0.29\n",
            "Ridge Regression: MSE=126648.59, R2=0.30\n",
            "Lasso Regression: MSE=126779.46, R2=0.30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-4-aaa06eb4ad79>:12: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  hitters['League'] = le.fit_transform(hitters['League'])\n",
            "<ipython-input-4-aaa06eb4ad79>:13: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  hitters['Division'] = le.fit_transform(hitters['Division'])\n",
            "<ipython-input-4-aaa06eb4ad79>:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  hitters['NewLeague'] = le.fit_transform(hitters['NewLeague'])\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_coordinate_descent.py:697: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.248e+04, tolerance: 4.367e+03\n",
            "  model = cd_fast.enet_coordinate_descent(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Q3\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import RidgeCV, LassoCV\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "boston = pd.read_csv('Boston_Housing.csv')\n",
        "\n",
        "print(\"Dataset Shape:\", boston.shape)\n",
        "print(\"Checking for missing values:\\n\", boston.isnull().sum())\n",
        "\n",
        "X = boston.drop('MEDV', axis=1)\n",
        "y = boston['MEDV']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "ridge_alphas = np.logspace(-6, 6, 13)\n",
        "lasso_alphas = np.logspace(-6, 6, 13)\n",
        "\n",
        "ridge_cv_model = RidgeCV(alphas=ridge_alphas, cv=5).fit(X_train, y_train)\n",
        "lasso_cv_model = LassoCV(alphas=lasso_alphas, cv=5, max_iter=10000).fit(X_train, y_train)\n",
        "\n",
        "models = {'RidgeCV': ridge_cv_model, 'LassoCV': lasso_cv_model}\n",
        "\n",
        "for name, model in models.items():\n",
        "    y_pred = model.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    r2 = r2_score(y_test, y_pred)\n",
        "    print(f\"{name}: Best Alpha={model.alpha_}, MSE={mse:.2f}, R²={r2:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3QgV85U1Wye",
        "outputId": "4ea16ae2-80a8-429c-8560-a9ce3e045798"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (506, 14)\n",
            "Checking for missing values:\n",
            " CRIM       0\n",
            "ZN         0\n",
            "INDUS      0\n",
            "CHAS       0\n",
            "NOX        0\n",
            "RM         0\n",
            "AGE        0\n",
            "DIS        0\n",
            "RAD        0\n",
            "TAX        0\n",
            "PTRATIO    0\n",
            "B          0\n",
            "LSTAT      0\n",
            "MEDV       0\n",
            "dtype: int64\n",
            "RidgeCV: Best Alpha=1.0, MSE=24.31, R²=0.67\n",
            "LassoCV: Best Alpha=1e-06, MSE=24.29, R²=0.67\n"
          ]
        }
      ]
    }
  ]
}